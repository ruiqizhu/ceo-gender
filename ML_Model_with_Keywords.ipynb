{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Model for Stock Return Prediction\n",
    "Using Richard's ceo_gender_file\n",
    "Incorporates certain hand-crafted keywords as additional variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import os\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import gensim\n",
    "import nltk\n",
    "import string\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleantxt(txt):\n",
    "    \"\"\"\n",
    "    Cleans the string passed. Cleaning Includes-\n",
    "    1. remove special characters/symbols\n",
    "    2. convert text to lower-case\n",
    "    3. retain only alphabets\n",
    "    4. remove words less than 3 characters\n",
    "    5. remove stop-words\n",
    "    \"\"\"  \n",
    "    # collecting english stop words from nltk-library\n",
    "    stpw = stopwords.words('english')\n",
    "    \n",
    "    # Adding custom stop-words\n",
    "    stpw.extend(['www','http','utc'])\n",
    "    stpw = set(stpw)\n",
    "    \n",
    "    # using regex to clean the text\n",
    "    txt = re.sub(r\"\\n\", \" \", txt)\n",
    "    txt = re.sub(\"[\\<\\[].*?[\\>\\]]\", \" \", txt)\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(r\"[^a-z ]\", \" \", txt)\n",
    "    txt = re.sub(r\"\\b\\w{1,3}\\b\", \" \",txt)\n",
    "    txt = \" \".join([x for x in txt.split() if x not in stpw])\n",
    "    return txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'biodiversity',\n",
       " 'carbon',\n",
       " 'carbon neutral',\n",
       " 'clean-up',\n",
       " 'climate change',\n",
       " 'code of ethic',\n",
       " 'corporate culture',\n",
       " 'corporate governance',\n",
       " 'corruption',\n",
       " 'discharge',\n",
       " 'diversity',\n",
       " 'divestment',\n",
       " 'emission',\n",
       " 'employee relation',\n",
       " 'enevery-efficiant',\n",
       " 'environmental',\n",
       " 'equality',\n",
       " 'esg',\n",
       " 'ethical',\n",
       " 'ethnics',\n",
       " 'fuel efficiency',\n",
       " 'gender',\n",
       " 'gender equality',\n",
       " 'governance risk',\n",
       " 'green energy',\n",
       " 'greenhouse',\n",
       " 'hazardous',\n",
       " 'health',\n",
       " 'human right',\n",
       " 'labor relation',\n",
       " 'labor standard',\n",
       " 'low carbon',\n",
       " 'natural resource',\n",
       " 'net-zero emission',\n",
       " 'pollution',\n",
       " 'race',\n",
       " 'remediation',\n",
       " 'renewable',\n",
       " 'renewable energy',\n",
       " 'responsible',\n",
       " 'safety',\n",
       " 'scandal',\n",
       " 'social',\n",
       " 'societal ',\n",
       " 'societal impact',\n",
       " 'sustainability',\n",
       " 'sustainable',\n",
       " 'tocis',\n",
       " 'transparency',\n",
       " 'waste',\n",
       " 'working condition',\n",
       " 'zero carbon'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in additional keywords\n",
    "esg_keywords = pd.read_excel(\"Keywords_ESG.xlsx\", index_col=None, header=None)\n",
    "esg_keywords = set(esg_keywords[0].unique())\n",
    "esg_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['generate', 'competitive', 'produce', 'steady', 'encourage',\n",
       "       'transparency', 'sufficient'], dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in keywords with extremity rating\n",
    "keywords_with_rating = pd.read_excel(\"keywords_conference.xlsx\", index_col=None, header=0)\n",
    "keywords_with_rating\n",
    "rate_5 = keywords_with_rating[5].dropna().unique()\n",
    "rate_4 = keywords_with_rating[4].dropna().unique()\n",
    "rate_3 = keywords_with_rating[3].dropna().unique()\n",
    "rate_2 = keywords_with_rating[2].dropna().unique()\n",
    "rate_1 = keywords_with_rating[1].dropna().unique()\n",
    "rate_minus1 = keywords_with_rating[-1].dropna().unique()\n",
    "rate_minus2 = keywords_with_rating[-2].dropna().unique()\n",
    "rate_minus3 = keywords_with_rating[-3].dropna().unique()\n",
    "rate_minus4 = keywords_with_rating[-4].dropna().unique()\n",
    "rate_minus5 = keywords_with_rating[-5].dropna().unique()\n",
    "rate_1\n",
    "#keyword_rate_dict = {rate_5: 5, rate_4: 4, rate_3: 3, rate_2: 2, rate_1: 1, rate_minus1: -1,\n",
    "                     #rate_minus2: -2, rate_minus3: -3, rate_minus4: -4, rate_minus5: -5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pid</th>\n",
       "      <th>CIK</th>\n",
       "      <th>cusip</th>\n",
       "      <th>CompName</th>\n",
       "      <th>folder_name</th>\n",
       "      <th>folder_path</th>\n",
       "      <th>at</th>\n",
       "      <th>lt</th>\n",
       "      <th>che</th>\n",
       "      <th>...</th>\n",
       "      <th>keyword_count_2</th>\n",
       "      <th>keyword_count_3</th>\n",
       "      <th>keyword_count_4</th>\n",
       "      <th>keyword_count_5</th>\n",
       "      <th>total_extreme</th>\n",
       "      <th>total_moderate</th>\n",
       "      <th>signed_extreme</th>\n",
       "      <th>signed_moderate</th>\n",
       "      <th>report_length</th>\n",
       "      <th>keyword_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000228.0</td>\n",
       "      <td>80640710</td>\n",
       "      <td>HENRY SCHEIN INC</td>\n",
       "      <td>0001000228-20-000018</td>\n",
       "      <td>QTR1\\0001000228-20-000018</td>\n",
       "      <td>7151.101</td>\n",
       "      <td>3233.706</td>\n",
       "      <td>106.097</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>146854.0</td>\n",
       "      <td>0.001444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>75252.0</td>\n",
       "      <td>69073210</td>\n",
       "      <td>OWENS &amp; MINOR INC/VA/</td>\n",
       "      <td>0000075252-20-000021</td>\n",
       "      <td>QTR1\\0000075252-20-000021</td>\n",
       "      <td>3643.084</td>\n",
       "      <td>3180.930</td>\n",
       "      <td>67.030</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70848.0</td>\n",
       "      <td>0.000240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>891024.0</td>\n",
       "      <td>70339510</td>\n",
       "      <td>PATTERSON COMPANIES, INC.</td>\n",
       "      <td>0000891024-20-000008</td>\n",
       "      <td>QTR2\\0000891024-20-000008</td>\n",
       "      <td>2715.350</td>\n",
       "      <td>1878.906</td>\n",
       "      <td>77.944</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>178435.0</td>\n",
       "      <td>0.000953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1000229.0</td>\n",
       "      <td>N2271710</td>\n",
       "      <td>CORE LABORATORIES N V</td>\n",
       "      <td>0001564590-20-004075</td>\n",
       "      <td>QTR1\\0001564590-20-004075</td>\n",
       "      <td>774.673</td>\n",
       "      <td>592.533</td>\n",
       "      <td>11.092</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65548.0</td>\n",
       "      <td>0.000809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1681459.0</td>\n",
       "      <td>G8711010</td>\n",
       "      <td>TechnipFMC plc</td>\n",
       "      <td>0001681459-20-000004</td>\n",
       "      <td>QTR1\\0001681459-20-000004</td>\n",
       "      <td>23518.800</td>\n",
       "      <td>15789.600</td>\n",
       "      <td>5239.900</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>139875.0</td>\n",
       "      <td>0.000293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>1227</td>\n",
       "      <td>1227</td>\n",
       "      <td>100493.0</td>\n",
       "      <td>90249410</td>\n",
       "      <td>TYSON FOODS, INC.</td>\n",
       "      <td>0000100493-20-000132</td>\n",
       "      <td>QTR4\\0000100493-20-000132</td>\n",
       "      <td>33097.000</td>\n",
       "      <td>18871.000</td>\n",
       "      <td>485.000</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98413.0</td>\n",
       "      <td>0.000640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>1228</td>\n",
       "      <td>1228</td>\n",
       "      <td>48465.0</td>\n",
       "      <td>44045210</td>\n",
       "      <td>HORMEL FOODS CORP /DE/</td>\n",
       "      <td>0000048465-20-000043</td>\n",
       "      <td>QTR4\\0000048465-20-000043</td>\n",
       "      <td>8109.004</td>\n",
       "      <td>2183.469</td>\n",
       "      <td>687.637</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39129.0</td>\n",
       "      <td>0.000511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>1229</td>\n",
       "      <td>1229</td>\n",
       "      <td>47518.0</td>\n",
       "      <td>43147510</td>\n",
       "      <td>Hill-Rom Holdings, Inc.</td>\n",
       "      <td>0000047518-20-000129</td>\n",
       "      <td>QTR4\\0000047518-20-000129</td>\n",
       "      <td>4919.000</td>\n",
       "      <td>3345.700</td>\n",
       "      <td>633.800</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75905.0</td>\n",
       "      <td>0.000962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>1230</td>\n",
       "      <td>1230</td>\n",
       "      <td>63296.0</td>\n",
       "      <td>57712810</td>\n",
       "      <td>MATTHEWS INTERNATIONAL CORP</td>\n",
       "      <td>0000063296-20-000098</td>\n",
       "      <td>QTR4\\0000063296-20-000098</td>\n",
       "      <td>2190.603</td>\n",
       "      <td>1471.367</td>\n",
       "      <td>35.302</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51732.0</td>\n",
       "      <td>0.000831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>1232</td>\n",
       "      <td>1232</td>\n",
       "      <td>72331.0</td>\n",
       "      <td>65566310</td>\n",
       "      <td>NORDSON CORP</td>\n",
       "      <td>0000072331-20-000024</td>\n",
       "      <td>QTR4\\0000072331-20-000024</td>\n",
       "      <td>3516.447</td>\n",
       "      <td>1935.402</td>\n",
       "      <td>151.164</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>74746.0</td>\n",
       "      <td>0.000602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1030 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index   pid        CIK     cusip                     CompName  \\\n",
       "0         0     0  1000228.0  80640710             HENRY SCHEIN INC   \n",
       "1         1     1    75252.0  69073210        OWENS & MINOR INC/VA/   \n",
       "2         2     2   891024.0  70339510    PATTERSON COMPANIES, INC.   \n",
       "3         3     3  1000229.0  N2271710        CORE LABORATORIES N V   \n",
       "4         5     5  1681459.0  G8711010               TechnipFMC plc   \n",
       "...     ...   ...        ...       ...                          ...   \n",
       "1025   1227  1227   100493.0  90249410            TYSON FOODS, INC.   \n",
       "1026   1228  1228    48465.0  44045210       HORMEL FOODS CORP /DE/   \n",
       "1027   1229  1229    47518.0  43147510      Hill-Rom Holdings, Inc.   \n",
       "1028   1230  1230    63296.0  57712810  MATTHEWS INTERNATIONAL CORP   \n",
       "1029   1232  1232    72331.0  65566310                 NORDSON CORP   \n",
       "\n",
       "               folder_name                folder_path         at         lt  \\\n",
       "0     0001000228-20-000018  QTR1\\0001000228-20-000018   7151.101   3233.706   \n",
       "1     0000075252-20-000021  QTR1\\0000075252-20-000021   3643.084   3180.930   \n",
       "2     0000891024-20-000008  QTR2\\0000891024-20-000008   2715.350   1878.906   \n",
       "3     0001564590-20-004075  QTR1\\0001564590-20-004075    774.673    592.533   \n",
       "4     0001681459-20-000004  QTR1\\0001681459-20-000004  23518.800  15789.600   \n",
       "...                    ...                        ...        ...        ...   \n",
       "1025  0000100493-20-000132  QTR4\\0000100493-20-000132  33097.000  18871.000   \n",
       "1026  0000048465-20-000043  QTR4\\0000048465-20-000043   8109.004   2183.469   \n",
       "1027  0000047518-20-000129  QTR4\\0000047518-20-000129   4919.000   3345.700   \n",
       "1028  0000063296-20-000098  QTR4\\0000063296-20-000098   2190.603   1471.367   \n",
       "1029  0000072331-20-000024  QTR4\\0000072331-20-000024   3516.447   1935.402   \n",
       "\n",
       "           che  ...  keyword_count_2  keyword_count_3  keyword_count_4  \\\n",
       "0      106.097  ...               35               16                9   \n",
       "1       67.030  ...               20                4                3   \n",
       "2       77.944  ...               53               10               12   \n",
       "3       11.092  ...               21                4                8   \n",
       "4     5239.900  ...               59                9               28   \n",
       "...        ...  ...              ...              ...              ...   \n",
       "1025   485.000  ...               37                7               16   \n",
       "1026   687.637  ...                8                5                2   \n",
       "1027   633.800  ...               21                9                6   \n",
       "1028    35.302  ...               12                6                2   \n",
       "1029   151.164  ...               34                9                3   \n",
       "\n",
       "     keyword_count_5 total_extreme total_moderate signed_extreme  \\\n",
       "0                  8             0              0              0   \n",
       "1                  4             0              0              0   \n",
       "2                  8             0              0              0   \n",
       "3                  3             0              0              0   \n",
       "4                 11             0              0              0   \n",
       "...              ...           ...            ...            ...   \n",
       "1025               1             0              0              0   \n",
       "1026               2             0              0              0   \n",
       "1027               2             0              0              0   \n",
       "1028               2             0              0              0   \n",
       "1029               2             0              0              0   \n",
       "\n",
       "      signed_moderate  report_length  keyword_perc  \n",
       "0                   0       146854.0      0.001444  \n",
       "1                   0        70848.0      0.000240  \n",
       "2                   0       178435.0      0.000953  \n",
       "3                   0        65548.0      0.000809  \n",
       "4                   0       139875.0      0.000293  \n",
       "...               ...            ...           ...  \n",
       "1025                0        98413.0      0.000640  \n",
       "1026                0        39129.0      0.000511  \n",
       "1027                0        75905.0      0.000962  \n",
       "1028                0        51732.0      0.000831  \n",
       "1029                0        74746.0      0.000602  \n",
       "\n",
       "[1030 rows x 55 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an array with (CIK: strategy text)\n",
    "corpus_dict = dict()\n",
    "corpus = [] # list of strategy text\n",
    "ncols = 0\n",
    "\n",
    "with open(\"ceo_gender_training.csv\") as f:\n",
    "    ncols = len(f.readline().split(','))\n",
    "ceo_data = pd.read_csv(\"ceo_gender_training.csv\")\n",
    "ceo_data.rename(columns={ceo_data.columns[0]: \"pid\" }, inplace = True)\n",
    "ceo_data['has_file'] = 0\n",
    "company_doc = []\n",
    "\n",
    "for i in range(-5, 6, 1):\n",
    "    if i == 0: continue\n",
    "    ceo_data['keyword_count_'+ str(i)] = 0\n",
    "ceo_data['total_extreme'] = 0\n",
    "ceo_data['total_moderate'] = 0\n",
    "ceo_data['signed_extreme'] = 0\n",
    "ceo_data['signed_moderate'] = 0\n",
    "\n",
    "    \n",
    "for index, row in ceo_data.iterrows():\n",
    "    folder_path = row['folder_path']\n",
    "    QTR = folder_path.split(\"\\\\\")[0]\n",
    "    CIK = folder_path.split(\"\\\\\")[1]\n",
    "    try:\n",
    "        f1 = open(QTR + \"/\" + CIK + \"/\" + \"business-section.txt\", \"r\")\n",
    "        business = f1.read()\n",
    "        f2 = open(QTR + \"/\" + CIK + \"/\" + \"risk-factors-section.txt\", \"r\")\n",
    "        risk = f2.read()\n",
    "        strategy = business + risk\n",
    "        ceo_data.at[index,'has_file'] = 1\n",
    "        clean_strategy = cleantxt(strategy)\n",
    "        corpus_dict[CIK] = clean_strategy\n",
    "        corpus.append(clean_strategy)\n",
    "        # report length and keywords\n",
    "        report_length = len(strategy)\n",
    "        ceo_data.at[index,'report_length'] = report_length\n",
    "        esg_word_count = 0\n",
    "        strategy_words = strategy.split()\n",
    "        for word in esg_keywords:\n",
    "            esg_word_count += strategy_words.count(word)\n",
    "        esg_word_perc = esg_word_count / report_length\n",
    "        ceo_data.at[index,'keyword_perc'] = esg_word_perc\n",
    "        # Add keyword data with extremity rating\n",
    "        for rating in range(-5, 6, 1):\n",
    "            if rating == 0: continue\n",
    "            word_count = 0\n",
    "            rate_words = keywords_with_rating[rating].dropna().unique()\n",
    "            for word in rate_words:\n",
    "                word_count += strategy_words.count(word)\n",
    "            col_name = 'keyword_count_'+ str(rating)\n",
    "            ceo_data.at[index, col_name] = word_count\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        ceo_data.at[index,'has_file'] = 0\n",
    "\n",
    "\n",
    "ceo_data['has_file'].unique()\n",
    "# consider only rows with the file data\n",
    "ceo_data2 = ceo_data.loc[ceo_data['has_file'] == 1].reset_index()\n",
    "#print(ceo_data2.shape)\n",
    "ceo_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(756, 15)\n",
      "(756, 1)\n"
     ]
    }
   ],
   "source": [
    "ceo_data2 = ceo_data2.dropna()\n",
    "for index, row in ceo_data2.iterrows():\n",
    "    rate_5 = ceo_data2.at[index, 'keyword_count_5']\n",
    "    rate_4 = ceo_data2.at[index, 'keyword_count_4']\n",
    "    rate_3 = ceo_data2.at[index, 'keyword_count_3']\n",
    "    rate_2 = ceo_data2.at[index, 'keyword_count_2']\n",
    "    rate_1 = ceo_data2.at[index, 'keyword_count_1']\n",
    "    rate_minus1 = ceo_data2.at[index, 'keyword_count_-1']\n",
    "    rate_minus2 = ceo_data2.at[index, 'keyword_count_-2']\n",
    "    rate_minus3 = ceo_data2.at[index, 'keyword_count_-3']\n",
    "    rate_minus4 = ceo_data2.at[index, 'keyword_count_-4']\n",
    "    rate_minus5 = ceo_data2.at[index, 'keyword_count_-5']\n",
    "    report_length = ceo_data2.at[index, 'report_length']\n",
    "    ceo_data2.at[index, 'total_extreme'] = (rate_5 + rate_4) / report_length\n",
    "    ceo_data2.at[index, 'total_moderate'] = (rate_1 + rate_2 + rate_3) / report_length\n",
    "    ceo_data2.at[index, 'signed_extreme'] = (rate_4 + rate_5 - rate_minus4 - rate_minus5) / report_length\n",
    "    ceo_data2.at[index, 'signed_moderate'] = (rate_1 + rate_2 + rate_3 + \n",
    "                                            rate_minus1 + rate_minus2 + rate_minus3) / report_length\n",
    "    \n",
    "ceo_data_small = ceo_data2[[\"ret_0220_0325\", \"at\", \"lt\", \"che\", \"ni\", \"sale\", \"execrank\", \"exchange_id\", \n",
    "                            \"gender_id\", \"state_id\", \"days_becameceo\", \"zip\", \"FF_48\", \"shrout_0220\",\n",
    "                            \"report_length\", \"keyword_perc\"]]\n",
    "                            #\"total_extreme\", \"total_moderate\", \"signed_extreme\", \"signed_moderate\"]]\n",
    "\n",
    "cleaned_data = ceo_data_small.dropna()\n",
    "    \n",
    "X = cleaned_data.iloc[:,1:]\n",
    "y = cleaned_data.iloc[:,0:1]\n",
    "# split trian and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "76/76 [==============================] - 0s 643us/step - loss: 0.1980 - mean_squared_error: 0.1980\n",
      "Epoch 2/150\n",
      "76/76 [==============================] - 0s 612us/step - loss: 0.1530 - mean_squared_error: 0.1530\n",
      "Epoch 3/150\n",
      "76/76 [==============================] - 0s 603us/step - loss: 0.1399 - mean_squared_error: 0.1399\n",
      "Epoch 4/150\n",
      "76/76 [==============================] - 0s 667us/step - loss: 0.1338 - mean_squared_error: 0.1338\n",
      "Epoch 5/150\n",
      "76/76 [==============================] - 0s 651us/step - loss: 0.1325 - mean_squared_error: 0.1325\n",
      "Epoch 6/150\n",
      "76/76 [==============================] - 0s 644us/step - loss: 0.1364 - mean_squared_error: 0.1364\n",
      "Epoch 7/150\n",
      "76/76 [==============================] - 0s 600us/step - loss: 0.1378 - mean_squared_error: 0.1378\n",
      "Epoch 8/150\n",
      "76/76 [==============================] - 0s 613us/step - loss: 0.1388 - mean_squared_error: 0.1388\n",
      "Epoch 9/150\n",
      "76/76 [==============================] - 0s 628us/step - loss: 0.1412 - mean_squared_error: 0.1412\n",
      "Epoch 10/150\n",
      "76/76 [==============================] - 0s 627us/step - loss: 0.1381 - mean_squared_error: 0.1381\n",
      "Epoch 11/150\n",
      "76/76 [==============================] - 0s 589us/step - loss: 0.1409 - mean_squared_error: 0.1409\n",
      "Epoch 12/150\n",
      "76/76 [==============================] - 0s 639us/step - loss: 0.1375 - mean_squared_error: 0.1375\n",
      "Epoch 13/150\n",
      "76/76 [==============================] - 0s 606us/step - loss: 0.1455 - mean_squared_error: 0.1455\n",
      "Epoch 14/150\n",
      "76/76 [==============================] - 0s 622us/step - loss: 0.1415 - mean_squared_error: 0.1415\n",
      "Epoch 15/150\n",
      "76/76 [==============================] - 0s 790us/step - loss: 0.1395 - mean_squared_error: 0.1395\n",
      "Epoch 16/150\n",
      "76/76 [==============================] - 0s 765us/step - loss: 0.1388 - mean_squared_error: 0.1388\n",
      "Epoch 17/150\n",
      "76/76 [==============================] - 0s 782us/step - loss: 0.1420 - mean_squared_error: 0.1420\n",
      "Epoch 18/150\n",
      "76/76 [==============================] - 0s 776us/step - loss: 0.1366 - mean_squared_error: 0.1366\n",
      "Epoch 19/150\n",
      "76/76 [==============================] - 0s 704us/step - loss: 0.1506 - mean_squared_error: 0.1506\n",
      "Epoch 20/150\n",
      "76/76 [==============================] - 0s 758us/step - loss: 0.1461 - mean_squared_error: 0.1461\n",
      "Epoch 21/150\n",
      "76/76 [==============================] - 0s 720us/step - loss: 0.1431 - mean_squared_error: 0.1431\n",
      "Epoch 22/150\n",
      "76/76 [==============================] - 0s 650us/step - loss: 0.1430 - mean_squared_error: 0.1430\n",
      "Epoch 23/150\n",
      "76/76 [==============================] - 0s 713us/step - loss: 0.1430 - mean_squared_error: 0.1430\n",
      "Epoch 24/150\n",
      "76/76 [==============================] - 0s 678us/step - loss: 0.1428 - mean_squared_error: 0.1428\n",
      "Epoch 25/150\n",
      "76/76 [==============================] - 0s 639us/step - loss: 0.1399 - mean_squared_error: 0.1399\n",
      "Epoch 26/150\n",
      "76/76 [==============================] - 0s 623us/step - loss: 0.1431 - mean_squared_error: 0.1431\n",
      "Epoch 27/150\n",
      "76/76 [==============================] - 0s 688us/step - loss: 0.1348 - mean_squared_error: 0.1348\n",
      "Epoch 28/150\n",
      "76/76 [==============================] - 0s 782us/step - loss: 0.1393 - mean_squared_error: 0.1393\n",
      "Epoch 29/150\n",
      "76/76 [==============================] - 0s 817us/step - loss: 0.1471 - mean_squared_error: 0.1471\n",
      "Epoch 30/150\n",
      "76/76 [==============================] - 0s 769us/step - loss: 0.1354 - mean_squared_error: 0.1354\n",
      "Epoch 31/150\n",
      "76/76 [==============================] - 0s 771us/step - loss: 0.1382 - mean_squared_error: 0.1382\n",
      "Epoch 32/150\n",
      "76/76 [==============================] - 0s 722us/step - loss: 0.1445 - mean_squared_error: 0.1445\n",
      "Epoch 33/150\n",
      "76/76 [==============================] - 0s 736us/step - loss: 0.1399 - mean_squared_error: 0.1399\n",
      "Epoch 34/150\n",
      "76/76 [==============================] - 0s 604us/step - loss: 0.1438 - mean_squared_error: 0.1438\n",
      "Epoch 35/150\n",
      "76/76 [==============================] - 0s 686us/step - loss: 0.1389 - mean_squared_error: 0.1389\n",
      "Epoch 36/150\n",
      "76/76 [==============================] - 0s 603us/step - loss: 0.1415 - mean_squared_error: 0.1415\n",
      "Epoch 37/150\n",
      "76/76 [==============================] - 0s 640us/step - loss: 0.1420 - mean_squared_error: 0.1420\n",
      "Epoch 38/150\n",
      "76/76 [==============================] - 0s 618us/step - loss: 0.1445 - mean_squared_error: 0.1445\n",
      "Epoch 39/150\n",
      "76/76 [==============================] - 0s 613us/step - loss: 0.1387 - mean_squared_error: 0.1387\n",
      "Epoch 40/150\n",
      "76/76 [==============================] - 0s 622us/step - loss: 0.1306 - mean_squared_error: 0.1306\n",
      "Epoch 41/150\n",
      "76/76 [==============================] - 0s 631us/step - loss: 0.1419 - mean_squared_error: 0.1419\n",
      "Epoch 42/150\n",
      "76/76 [==============================] - 0s 734us/step - loss: 0.1432 - mean_squared_error: 0.1432\n",
      "Epoch 43/150\n",
      "76/76 [==============================] - 0s 726us/step - loss: 0.1396 - mean_squared_error: 0.1396\n",
      "Epoch 44/150\n",
      "76/76 [==============================] - 0s 754us/step - loss: 0.1459 - mean_squared_error: 0.1459\n",
      "Epoch 45/150\n",
      "76/76 [==============================] - 0s 759us/step - loss: 0.1389 - mean_squared_error: 0.1389\n",
      "Epoch 46/150\n",
      "76/76 [==============================] - 0s 748us/step - loss: 0.1408 - mean_squared_error: 0.1408\n",
      "Epoch 47/150\n",
      "76/76 [==============================] - 0s 729us/step - loss: 0.1430 - mean_squared_error: 0.1430\n",
      "Epoch 48/150\n",
      "76/76 [==============================] - 0s 630us/step - loss: 0.1427 - mean_squared_error: 0.1427\n",
      "Epoch 49/150\n",
      "76/76 [==============================] - 0s 697us/step - loss: 0.1377 - mean_squared_error: 0.1377\n",
      "Epoch 50/150\n",
      "76/76 [==============================] - 0s 655us/step - loss: 0.1427 - mean_squared_error: 0.1427\n",
      "Epoch 51/150\n",
      "76/76 [==============================] - 0s 615us/step - loss: 0.1363 - mean_squared_error: 0.1363\n",
      "Epoch 52/150\n",
      "76/76 [==============================] - 0s 635us/step - loss: 0.1307 - mean_squared_error: 0.1307\n",
      "Epoch 53/150\n",
      "76/76 [==============================] - 0s 636us/step - loss: 0.1430 - mean_squared_error: 0.1430\n",
      "Epoch 54/150\n",
      "76/76 [==============================] - 0s 599us/step - loss: 0.1369 - mean_squared_error: 0.1369\n",
      "Epoch 55/150\n",
      "76/76 [==============================] - 0s 557us/step - loss: 0.1426 - mean_squared_error: 0.1426\n",
      "Epoch 56/150\n",
      "76/76 [==============================] - 0s 550us/step - loss: 0.1430 - mean_squared_error: 0.1430\n",
      "Epoch 57/150\n",
      "76/76 [==============================] - 0s 578us/step - loss: 0.1439 - mean_squared_error: 0.1439\n",
      "Epoch 58/150\n",
      "76/76 [==============================] - 0s 594us/step - loss: 0.1393 - mean_squared_error: 0.1393\n",
      "Epoch 59/150\n",
      "76/76 [==============================] - 0s 607us/step - loss: 0.1371 - mean_squared_error: 0.1371\n",
      "Epoch 60/150\n",
      "76/76 [==============================] - 0s 581us/step - loss: 0.1535 - mean_squared_error: 0.1535\n",
      "Epoch 61/150\n",
      "76/76 [==============================] - 0s 622us/step - loss: 0.1382 - mean_squared_error: 0.1382\n",
      "Epoch 62/150\n",
      "76/76 [==============================] - 0s 648us/step - loss: 0.1407 - mean_squared_error: 0.1407\n",
      "Epoch 63/150\n",
      "76/76 [==============================] - 0s 705us/step - loss: 0.1363 - mean_squared_error: 0.1363\n",
      "Epoch 64/150\n",
      "76/76 [==============================] - 0s 668us/step - loss: 0.1429 - mean_squared_error: 0.1429\n",
      "Epoch 65/150\n",
      "76/76 [==============================] - 0s 716us/step - loss: 0.1359 - mean_squared_error: 0.1359\n",
      "Epoch 66/150\n",
      "76/76 [==============================] - 0s 656us/step - loss: 0.1452 - mean_squared_error: 0.1452\n",
      "Epoch 67/150\n",
      "76/76 [==============================] - 0s 658us/step - loss: 0.1402 - mean_squared_error: 0.1402\n",
      "Epoch 68/150\n",
      "76/76 [==============================] - 0s 681us/step - loss: 0.1441 - mean_squared_error: 0.1441\n",
      "Epoch 69/150\n",
      "76/76 [==============================] - 0s 656us/step - loss: 0.1420 - mean_squared_error: 0.1420\n",
      "Epoch 70/150\n",
      "76/76 [==============================] - 0s 652us/step - loss: 0.1390 - mean_squared_error: 0.1390\n",
      "Epoch 71/150\n",
      "76/76 [==============================] - 0s 679us/step - loss: 0.1354 - mean_squared_error: 0.1354\n",
      "Epoch 72/150\n",
      "76/76 [==============================] - 0s 635us/step - loss: 0.1362 - mean_squared_error: 0.1362\n",
      "Epoch 73/150\n",
      "76/76 [==============================] - 0s 652us/step - loss: 0.1356 - mean_squared_error: 0.1356\n",
      "Epoch 74/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 649us/step - loss: 0.1372 - mean_squared_error: 0.1372\n",
      "Epoch 75/150\n",
      "76/76 [==============================] - 0s 645us/step - loss: 0.1363 - mean_squared_error: 0.1363\n",
      "Epoch 76/150\n",
      "76/76 [==============================] - 0s 587us/step - loss: 0.1444 - mean_squared_error: 0.1444\n",
      "Epoch 77/150\n",
      "76/76 [==============================] - 0s 685us/step - loss: 0.1389 - mean_squared_error: 0.1389\n",
      "Epoch 78/150\n",
      "76/76 [==============================] - 0s 786us/step - loss: 0.1491 - mean_squared_error: 0.1491\n",
      "Epoch 79/150\n",
      "76/76 [==============================] - 0s 718us/step - loss: 0.1449 - mean_squared_error: 0.1449\n",
      "Epoch 80/150\n",
      "76/76 [==============================] - 0s 696us/step - loss: 0.1361 - mean_squared_error: 0.1361\n",
      "Epoch 81/150\n",
      "76/76 [==============================] - 0s 650us/step - loss: 0.1394 - mean_squared_error: 0.1394\n",
      "Epoch 82/150\n",
      "76/76 [==============================] - 0s 570us/step - loss: 0.1413 - mean_squared_error: 0.1413\n",
      "Epoch 83/150\n",
      "76/76 [==============================] - 0s 648us/step - loss: 0.1392 - mean_squared_error: 0.1392\n",
      "Epoch 84/150\n",
      "76/76 [==============================] - 0s 583us/step - loss: 0.1352 - mean_squared_error: 0.1352\n",
      "Epoch 85/150\n",
      "76/76 [==============================] - 0s 633us/step - loss: 0.1446 - mean_squared_error: 0.1446\n",
      "Epoch 86/150\n",
      "76/76 [==============================] - 0s 560us/step - loss: 0.1308 - mean_squared_error: 0.1308\n",
      "Epoch 87/150\n",
      "76/76 [==============================] - 0s 581us/step - loss: 0.1434 - mean_squared_error: 0.1434\n",
      "Epoch 88/150\n",
      "76/76 [==============================] - 0s 554us/step - loss: 0.1419 - mean_squared_error: 0.1419\n",
      "Epoch 89/150\n",
      "76/76 [==============================] - 0s 600us/step - loss: 0.1380 - mean_squared_error: 0.1380\n",
      "Epoch 90/150\n",
      "76/76 [==============================] - 0s 555us/step - loss: 0.1432 - mean_squared_error: 0.1432\n",
      "Epoch 91/150\n",
      "76/76 [==============================] - 0s 591us/step - loss: 0.1389 - mean_squared_error: 0.1389\n",
      "Epoch 92/150\n",
      "76/76 [==============================] - 0s 623us/step - loss: 0.1389 - mean_squared_error: 0.1389\n",
      "Epoch 93/150\n",
      "76/76 [==============================] - 0s 573us/step - loss: 0.1351 - mean_squared_error: 0.1351\n",
      "Epoch 94/150\n",
      "76/76 [==============================] - 0s 622us/step - loss: 0.1395 - mean_squared_error: 0.1395\n",
      "Epoch 95/150\n",
      "76/76 [==============================] - 0s 607us/step - loss: 0.1420 - mean_squared_error: 0.1420\n",
      "Epoch 96/150\n",
      "76/76 [==============================] - 0s 781us/step - loss: 0.1335 - mean_squared_error: 0.1335\n",
      "Epoch 97/150\n",
      "76/76 [==============================] - 0s 805us/step - loss: 0.1453 - mean_squared_error: 0.1453\n",
      "Epoch 98/150\n",
      "76/76 [==============================] - 0s 810us/step - loss: 0.1398 - mean_squared_error: 0.1398\n",
      "Epoch 99/150\n",
      "76/76 [==============================] - 0s 710us/step - loss: 0.1385 - mean_squared_error: 0.1385\n",
      "Epoch 100/150\n",
      "76/76 [==============================] - 0s 740us/step - loss: 0.1410 - mean_squared_error: 0.1410\n",
      "Epoch 101/150\n",
      "76/76 [==============================] - 0s 750us/step - loss: 0.1368 - mean_squared_error: 0.1368\n",
      "Epoch 102/150\n",
      "76/76 [==============================] - 0s 642us/step - loss: 0.1451 - mean_squared_error: 0.1451\n",
      "Epoch 103/150\n",
      "76/76 [==============================] - 0s 682us/step - loss: 0.1372 - mean_squared_error: 0.1372\n",
      "Epoch 104/150\n",
      "76/76 [==============================] - 0s 708us/step - loss: 0.1371 - mean_squared_error: 0.1371\n",
      "Epoch 105/150\n",
      "76/76 [==============================] - 0s 659us/step - loss: 0.1368 - mean_squared_error: 0.1368\n",
      "Epoch 106/150\n",
      "76/76 [==============================] - 0s 655us/step - loss: 0.1353 - mean_squared_error: 0.1353\n",
      "Epoch 107/150\n",
      "76/76 [==============================] - 0s 665us/step - loss: 0.1449 - mean_squared_error: 0.1449\n",
      "Epoch 108/150\n",
      "76/76 [==============================] - 0s 652us/step - loss: 0.1402 - mean_squared_error: 0.1402\n",
      "Epoch 109/150\n",
      "76/76 [==============================] - 0s 714us/step - loss: 0.1378 - mean_squared_error: 0.1378\n",
      "Epoch 110/150\n",
      "76/76 [==============================] - 0s 735us/step - loss: 0.1465 - mean_squared_error: 0.1465\n",
      "Epoch 111/150\n",
      "76/76 [==============================] - 0s 607us/step - loss: 0.1534 - mean_squared_error: 0.1534\n",
      "Epoch 112/150\n",
      "76/76 [==============================] - 0s 546us/step - loss: 0.1382 - mean_squared_error: 0.1382\n",
      "Epoch 113/150\n",
      "76/76 [==============================] - 0s 586us/step - loss: 0.1372 - mean_squared_error: 0.1372\n",
      "Epoch 114/150\n",
      "76/76 [==============================] - 0s 598us/step - loss: 0.1407 - mean_squared_error: 0.1407\n",
      "Epoch 115/150\n",
      "76/76 [==============================] - 0s 638us/step - loss: 0.1434 - mean_squared_error: 0.1434\n",
      "Epoch 116/150\n",
      "76/76 [==============================] - 0s 628us/step - loss: 0.1383 - mean_squared_error: 0.1383\n",
      "Epoch 117/150\n",
      "76/76 [==============================] - 0s 711us/step - loss: 0.1433 - mean_squared_error: 0.1433\n",
      "Epoch 118/150\n",
      "76/76 [==============================] - 0s 656us/step - loss: 0.1467 - mean_squared_error: 0.1467\n",
      "Epoch 119/150\n",
      "76/76 [==============================] - 0s 654us/step - loss: 0.1338 - mean_squared_error: 0.1338\n",
      "Epoch 120/150\n",
      "76/76 [==============================] - 0s 606us/step - loss: 0.1418 - mean_squared_error: 0.1418\n",
      "Epoch 121/150\n",
      "76/76 [==============================] - 0s 551us/step - loss: 0.1373 - mean_squared_error: 0.1373\n",
      "Epoch 122/150\n",
      "76/76 [==============================] - 0s 577us/step - loss: 0.1393 - mean_squared_error: 0.1393\n",
      "Epoch 123/150\n",
      "76/76 [==============================] - 0s 609us/step - loss: 0.1367 - mean_squared_error: 0.1367\n",
      "Epoch 124/150\n",
      "76/76 [==============================] - 0s 587us/step - loss: 0.1347 - mean_squared_error: 0.1347\n",
      "Epoch 125/150\n",
      "76/76 [==============================] - 0s 592us/step - loss: 0.1432 - mean_squared_error: 0.1432\n",
      "Epoch 126/150\n",
      "76/76 [==============================] - 0s 589us/step - loss: 0.1381 - mean_squared_error: 0.1381\n",
      "Epoch 127/150\n",
      "76/76 [==============================] - 0s 580us/step - loss: 0.1455 - mean_squared_error: 0.1455\n",
      "Epoch 128/150\n",
      "76/76 [==============================] - 0s 639us/step - loss: 0.1364 - mean_squared_error: 0.1364\n",
      "Epoch 129/150\n",
      "76/76 [==============================] - 0s 594us/step - loss: 0.1393 - mean_squared_error: 0.1393\n",
      "Epoch 130/150\n",
      "76/76 [==============================] - 0s 606us/step - loss: 0.1384 - mean_squared_error: 0.1384\n",
      "Epoch 131/150\n",
      "76/76 [==============================] - 0s 622us/step - loss: 0.1405 - mean_squared_error: 0.1405\n",
      "Epoch 132/150\n",
      "76/76 [==============================] - 0s 637us/step - loss: 0.1360 - mean_squared_error: 0.1360\n",
      "Epoch 133/150\n",
      "76/76 [==============================] - 0s 716us/step - loss: 0.1338 - mean_squared_error: 0.1338\n",
      "Epoch 134/150\n",
      "76/76 [==============================] - 0s 619us/step - loss: 0.1439 - mean_squared_error: 0.1439\n",
      "Epoch 135/150\n",
      "76/76 [==============================] - 0s 559us/step - loss: 0.1425 - mean_squared_error: 0.1425\n",
      "Epoch 136/150\n",
      "76/76 [==============================] - 0s 628us/step - loss: 0.1332 - mean_squared_error: 0.1332\n",
      "Epoch 137/150\n",
      "76/76 [==============================] - 0s 583us/step - loss: 0.1422 - mean_squared_error: 0.1422\n",
      "Epoch 138/150\n",
      "76/76 [==============================] - 0s 545us/step - loss: 0.1357 - mean_squared_error: 0.1357\n",
      "Epoch 139/150\n",
      "76/76 [==============================] - 0s 651us/step - loss: 0.1381 - mean_squared_error: 0.1381\n",
      "Epoch 140/150\n",
      "76/76 [==============================] - 0s 637us/step - loss: 0.1380 - mean_squared_error: 0.1380\n",
      "Epoch 141/150\n",
      "76/76 [==============================] - 0s 586us/step - loss: 0.1390 - mean_squared_error: 0.1390\n",
      "Epoch 142/150\n",
      "76/76 [==============================] - 0s 595us/step - loss: 0.1361 - mean_squared_error: 0.1361\n",
      "Epoch 143/150\n",
      "76/76 [==============================] - 0s 557us/step - loss: 0.1444 - mean_squared_error: 0.1444\n",
      "Epoch 144/150\n",
      "76/76 [==============================] - 0s 679us/step - loss: 0.1367 - mean_squared_error: 0.1367\n",
      "Epoch 145/150\n",
      "76/76 [==============================] - 0s 551us/step - loss: 0.1460 - mean_squared_error: 0.1460\n",
      "Epoch 146/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 569us/step - loss: 0.1432 - mean_squared_error: 0.1432\n",
      "Epoch 147/150\n",
      "76/76 [==============================] - 0s 609us/step - loss: 0.1372 - mean_squared_error: 0.1372\n",
      "Epoch 148/150\n",
      "76/76 [==============================] - 0s 577us/step - loss: 0.1379 - mean_squared_error: 0.1379\n",
      "Epoch 149/150\n",
      "76/76 [==============================] - 0s 556us/step - loss: 0.1428 - mean_squared_error: 0.1428\n",
      "Epoch 150/150\n",
      "76/76 [==============================] - 0s 591us/step - loss: 0.1494 - mean_squared_error: 0.1494\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff8e0c75040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1546 - mean_squared_error: 0.1546\n",
      "test loss, test mse: [0.15458044409751892, 0.15458044409751892]\n"
     ]
    }
   ],
   "source": [
    "# define the keras model for deep learning\n",
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=15, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the keras model\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=['mean_squared_error'])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=10)\n",
    "\n",
    "# evaluate the keras model\n",
    "# _, mse = model.evaluate(X_test, y_test)\n",
    "# print('MSE: %.2f' % (mse*100))\n",
    "results = model.evaluate(X_test, y_test, batch_size=128)\n",
    "print(\"test loss, test mse:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.023183\n"
     ]
    }
   ],
   "source": [
    "# run the data on xgboost model\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "\n",
    "# train xgb classifier\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 100)\n",
    "xg_reg.fit(X_train,y_train)\n",
    "\n",
    "preds = xg_reg.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, preds)\n",
    "print(\"MSE: %f\" % (mse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.024433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "regr = svm.SVR()\n",
    "regr.fit(X_train, y_train)\n",
    "preds = regr.predict(X_test)\n",
    "mse = mean_squared_error(y_test, preds)\n",
    "print(\"MSE: %f\" % (mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.024261\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "from sklearn.linear_model import Ridge\n",
    "clf = Ridge(alpha=1.0)\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_test)\n",
    "mse = mean_squared_error(y_test, preds)\n",
    "print(\"MSE: %f\" % (mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>ret_0220_0325</td>  <th>  R-squared (uncentered):</th>      <td>   0.833</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.830</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   309.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 12 Apr 2021</td> <th>  Prob (F-statistic):</th>           <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:42:12</td>     <th>  Log-Likelihood:    </th>          <td>  423.22</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   946</td>      <th>  AIC:               </th>          <td>  -816.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   931</td>      <th>  BIC:               </th>          <td>  -743.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>at</th>             <td>-1.265e-07</td> <td> 4.75e-07</td> <td>   -0.266</td> <td> 0.790</td> <td>-1.06e-06</td> <td> 8.05e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lt</th>             <td>-4.937e-07</td> <td> 7.35e-07</td> <td>   -0.671</td> <td> 0.502</td> <td>-1.94e-06</td> <td> 9.49e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>che</th>            <td>-6.548e-07</td> <td> 1.18e-06</td> <td>   -0.557</td> <td> 0.578</td> <td>-2.96e-06</td> <td> 1.65e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ni</th>             <td> 4.172e-06</td> <td> 3.22e-06</td> <td>    1.295</td> <td> 0.195</td> <td>-2.15e-06</td> <td> 1.05e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sale</th>           <td> 7.809e-07</td> <td> 2.75e-07</td> <td>    2.836</td> <td> 0.005</td> <td> 2.41e-07</td> <td> 1.32e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>execrank</th>       <td>   -0.0082</td> <td>    0.006</td> <td>   -1.470</td> <td> 0.142</td> <td>   -0.019</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exchange_id</th>    <td>   -0.0789</td> <td>    0.009</td> <td>   -8.554</td> <td> 0.000</td> <td>   -0.097</td> <td>   -0.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender_id</th>      <td>   -0.0660</td> <td>    0.019</td> <td>   -3.566</td> <td> 0.000</td> <td>   -0.102</td> <td>   -0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>state_id</th>       <td>   -0.0015</td> <td>    0.000</td> <td>   -4.330</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>days_becameceo</th> <td> 8.209e-07</td> <td> 1.72e-06</td> <td>    0.477</td> <td> 0.633</td> <td>-2.56e-06</td> <td>  4.2e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zip</th>            <td>-8.172e-07</td> <td> 1.59e-07</td> <td>   -5.136</td> <td> 0.000</td> <td>-1.13e-06</td> <td>-5.05e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FF_48</th>          <td>   -0.0021</td> <td>    0.000</td> <td>   -5.332</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>shrout_0220</th>    <td> 2.757e-08</td> <td> 1.28e-08</td> <td>    2.160</td> <td> 0.031</td> <td> 2.52e-09</td> <td> 5.26e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>report_length</th>  <td>  -3.8e-08</td> <td> 6.34e-08</td> <td>   -0.599</td> <td> 0.549</td> <td>-1.62e-07</td> <td> 8.65e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>keyword_perc</th>   <td>  -44.6351</td> <td>   15.384</td> <td>   -2.901</td> <td> 0.004</td> <td>  -74.827</td> <td>  -14.443</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 8.933</td> <th>  Durbin-Watson:     </th> <td>   1.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.011</td> <th>  Jarque-Bera (JB):  </th> <td>  12.558</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.056</td> <th>  Prob(JB):          </th> <td> 0.00188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.553</td> <th>  Cond. No.          </th> <td>2.02e+09</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[3] The condition number is large, 2.02e+09. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:          ret_0220_0325   R-squared (uncentered):                   0.833\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.830\n",
       "Method:                 Least Squares   F-statistic:                              309.6\n",
       "Date:                Mon, 12 Apr 2021   Prob (F-statistic):                        0.00\n",
       "Time:                        23:42:12   Log-Likelihood:                          423.22\n",
       "No. Observations:                 946   AIC:                                     -816.4\n",
       "Df Residuals:                     931   BIC:                                     -743.7\n",
       "Df Model:                          15                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==================================================================================\n",
       "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "at             -1.265e-07   4.75e-07     -0.266      0.790   -1.06e-06    8.05e-07\n",
       "lt             -4.937e-07   7.35e-07     -0.671      0.502   -1.94e-06    9.49e-07\n",
       "che            -6.548e-07   1.18e-06     -0.557      0.578   -2.96e-06    1.65e-06\n",
       "ni              4.172e-06   3.22e-06      1.295      0.195   -2.15e-06    1.05e-05\n",
       "sale            7.809e-07   2.75e-07      2.836      0.005    2.41e-07    1.32e-06\n",
       "execrank          -0.0082      0.006     -1.470      0.142      -0.019       0.003\n",
       "exchange_id       -0.0789      0.009     -8.554      0.000      -0.097      -0.061\n",
       "gender_id         -0.0660      0.019     -3.566      0.000      -0.102      -0.030\n",
       "state_id          -0.0015      0.000     -4.330      0.000      -0.002      -0.001\n",
       "days_becameceo  8.209e-07   1.72e-06      0.477      0.633   -2.56e-06     4.2e-06\n",
       "zip            -8.172e-07   1.59e-07     -5.136      0.000   -1.13e-06   -5.05e-07\n",
       "FF_48             -0.0021      0.000     -5.332      0.000      -0.003      -0.001\n",
       "shrout_0220     2.757e-08   1.28e-08      2.160      0.031    2.52e-09    5.26e-08\n",
       "report_length    -3.8e-08   6.34e-08     -0.599      0.549   -1.62e-07    8.65e-08\n",
       "keyword_perc     -44.6351     15.384     -2.901      0.004     -74.827     -14.443\n",
       "==============================================================================\n",
       "Omnibus:                        8.933   Durbin-Watson:                   1.648\n",
       "Prob(Omnibus):                  0.011   Jarque-Bera (JB):               12.558\n",
       "Skew:                          -0.056   Prob(JB):                      0.00188\n",
       "Kurtosis:                       3.553   Cond. No.                     2.02e+09\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[3] The condition number is large, 2.02e+09. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear regression to look at coefficient result\n",
    "import statsmodels.api as sm\n",
    "#X = sm.add_constant(X.ravel())\n",
    "results = sm.OLS(y,X).fit()\n",
    "results.summary()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
