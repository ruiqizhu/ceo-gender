{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5H_laM71Sp7"
   },
   "source": [
    "### ML Model for Stock Return Prediction\n",
    "Using Richard's ceo_gender_file\n",
    "Try to predict stock return using the available variables\n",
    "#### Data Description\n",
    "* 1236 records\n",
    "#### Predictors that I use\n",
    "* at\n",
    "* lt\n",
    "* che\n",
    "* ni\n",
    "* sale\n",
    "* execrank\n",
    "* exchange_id\n",
    "* gender_id\n",
    "* state_id\n",
    "* days_becameceo\n",
    "* zip\n",
    "* FF_48\n",
    "* shrout_0220\n",
    "Y: ret_0220_0325"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "0wfaDuBv1SqA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import os\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "atUT4ULC1SqB",
    "outputId": "2fc688a6-ed44-4cb1-a626-9372299da52b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['QTR2', 'QTR4', 'QTR3', 'header_info.xlsx', '.DS_Store', '~$header_info.xlsx', 'ML_Model_with_Text.ipynb', 'LDA_Topic_Modeling.ipynb', 'QTR1', 'Gender_Classification_with_Sentiment.ipynb', 'ML_Model_Stock_Return.ipynb', '.ipynb_checkpoints', 'Gender_Classification_Using_Text.ipynb', 'Gender_Classification_Without_Text.ipynb', 'ceo_gender_training.csv']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "at                float64\n",
       "lt                float64\n",
       "che               float64\n",
       "ni                float64\n",
       "sale              float64\n",
       "execrank          float64\n",
       "exchange_id         int64\n",
       "gender_id           int64\n",
       "state_id            int64\n",
       "days_becameceo    float64\n",
       "zip                 int64\n",
       "FF_48               int64\n",
       "shrout_0220       float64\n",
       "ret_0220_0325     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data\n",
    "print(os.listdir())\n",
    "ncols = 0\n",
    "with open(\"ceo_gender_training.csv\") as f:\n",
    "    ncols = len(f.readline().split(','))\n",
    "ceo_data = pd.read_csv(\"ceo_gender_training.csv\")\n",
    "ceo_data.rename(columns={ceo_data.columns[0]: \"pid\" }, inplace = True)\n",
    "ceo_data_small = ceo_data[[\"at\", \"lt\", \"che\", \"ni\", \"sale\", \"execrank\", \"exchange_id\", \n",
    "                           \"gender_id\", \"state_id\", \"days_becameceo\", \"zip\", \"FF_48\", \"shrout_0220\", \"ret_0220_0325\"]]\n",
    "ceo_data_small.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4u2uvwD4rKH"
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0VEEWh5E1SqC",
    "outputId": "38826207-b242-48ca-80c5-bbfd1f65dd5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.151101e+03 3.233706e+03 1.060970e+02 ... 1.174700e+04 4.100000e+01\n",
      "  1.433910e+05]\n",
      " [3.643084e+03 3.180930e+03 6.703000e+01 ... 2.311600e+04 4.100000e+01\n",
      "  6.285200e+04]\n",
      " [2.715350e+03 1.878906e+03 7.794400e+01 ... 5.512000e+04 4.100000e+01\n",
      "  9.579200e+04]\n",
      " ...\n",
      " [2.190603e+03 1.471367e+03 3.530200e+01 ... 1.521200e+04 8.000000e+00\n",
      "  3.129000e+04]\n",
      " [6.274500e+03 2.645900e+03 8.950000e+01 ... 9.458300e+04 1.200000e+01\n",
      "  4.906200e+04]\n",
      " [3.516447e+03 1.935402e+03 1.511640e+02 ... 4.414500e+04 2.100000e+01\n",
      "  5.785800e+04]]\n"
     ]
    }
   ],
   "source": [
    "data = np.array(ceo_data_small)\n",
    "data = data[~np.isnan(data).any(axis=1)]\n",
    "X = data[:,0:13]\n",
    "y = data[:,13]\n",
    "# split trian and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "eacDQ-aK1SqC"
   },
   "outputs": [],
   "source": [
    "# define the keras model for deep learning\n",
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=13, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mr5bBS9J5KM-",
    "outputId": "345941d0-943e-4522-c496-428939d0c406"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "94/94 [==============================] - 0s 817us/step - loss: 0.1547 - mean_squared_error: 0.1547\n",
      "Epoch 2/150\n",
      "94/94 [==============================] - 0s 591us/step - loss: 0.1563 - mean_squared_error: 0.1563\n",
      "Epoch 3/150\n",
      "94/94 [==============================] - 0s 636us/step - loss: 0.1527 - mean_squared_error: 0.1527\n",
      "Epoch 4/150\n",
      "94/94 [==============================] - 0s 581us/step - loss: 0.1440 - mean_squared_error: 0.1440\n",
      "Epoch 5/150\n",
      "94/94 [==============================] - 0s 771us/step - loss: 0.1505 - mean_squared_error: 0.1505\n",
      "Epoch 6/150\n",
      "94/94 [==============================] - 0s 560us/step - loss: 0.1461 - mean_squared_error: 0.1461\n",
      "Epoch 7/150\n",
      "94/94 [==============================] - 0s 623us/step - loss: 0.1485 - mean_squared_error: 0.1485\n",
      "Epoch 8/150\n",
      "94/94 [==============================] - 0s 588us/step - loss: 0.1516 - mean_squared_error: 0.1516\n",
      "Epoch 9/150\n",
      "94/94 [==============================] - 0s 557us/step - loss: 0.1461 - mean_squared_error: 0.1461\n",
      "Epoch 10/150\n",
      "94/94 [==============================] - 0s 606us/step - loss: 0.1524 - mean_squared_error: 0.1524\n",
      "Epoch 11/150\n",
      "94/94 [==============================] - 0s 579us/step - loss: 0.1401 - mean_squared_error: 0.1401\n",
      "Epoch 12/150\n",
      "94/94 [==============================] - 0s 647us/step - loss: 0.1521 - mean_squared_error: 0.1521\n",
      "Epoch 13/150\n",
      "94/94 [==============================] - 0s 570us/step - loss: 0.1471 - mean_squared_error: 0.1471\n",
      "Epoch 14/150\n",
      "94/94 [==============================] - 0s 596us/step - loss: 0.1503 - mean_squared_error: 0.1503\n",
      "Epoch 15/150\n",
      "94/94 [==============================] - 0s 550us/step - loss: 0.1432 - mean_squared_error: 0.1432\n",
      "Epoch 16/150\n",
      "94/94 [==============================] - 0s 606us/step - loss: 0.1492 - mean_squared_error: 0.1492\n",
      "Epoch 17/150\n",
      "94/94 [==============================] - 0s 569us/step - loss: 0.1557 - mean_squared_error: 0.1557\n",
      "Epoch 18/150\n",
      "94/94 [==============================] - 0s 632us/step - loss: 0.1485 - mean_squared_error: 0.1485\n",
      "Epoch 19/150\n",
      "94/94 [==============================] - 0s 565us/step - loss: 0.1449 - mean_squared_error: 0.1449\n",
      "Epoch 20/150\n",
      "94/94 [==============================] - 0s 575us/step - loss: 0.1550 - mean_squared_error: 0.1550\n",
      "Epoch 21/150\n",
      "94/94 [==============================] - 0s 780us/step - loss: 0.1502 - mean_squared_error: 0.1502\n",
      "Epoch 22/150\n",
      "94/94 [==============================] - 0s 764us/step - loss: 0.1465 - mean_squared_error: 0.1465\n",
      "Epoch 23/150\n",
      "94/94 [==============================] - 0s 766us/step - loss: 0.1469 - mean_squared_error: 0.1469\n",
      "Epoch 24/150\n",
      "94/94 [==============================] - 0s 627us/step - loss: 0.1518 - mean_squared_error: 0.1518\n",
      "Epoch 25/150\n",
      "94/94 [==============================] - 0s 567us/step - loss: 0.1495 - mean_squared_error: 0.1495\n",
      "Epoch 26/150\n",
      "94/94 [==============================] - 0s 586us/step - loss: 0.1513 - mean_squared_error: 0.1513\n",
      "Epoch 27/150\n",
      "94/94 [==============================] - 0s 690us/step - loss: 0.1542 - mean_squared_error: 0.1542\n",
      "Epoch 28/150\n",
      "94/94 [==============================] - 0s 830us/step - loss: 0.1468 - mean_squared_error: 0.1468\n",
      "Epoch 29/150\n",
      "94/94 [==============================] - 0s 775us/step - loss: 0.1479 - mean_squared_error: 0.1479\n",
      "Epoch 30/150\n",
      "94/94 [==============================] - 0s 598us/step - loss: 0.1511 - mean_squared_error: 0.1511\n",
      "Epoch 31/150\n",
      "94/94 [==============================] - 0s 574us/step - loss: 0.1438 - mean_squared_error: 0.1438\n",
      "Epoch 32/150\n",
      "94/94 [==============================] - 0s 733us/step - loss: 0.1513 - mean_squared_error: 0.1513\n",
      "Epoch 33/150\n",
      "94/94 [==============================] - 0s 684us/step - loss: 0.1561 - mean_squared_error: 0.1561\n",
      "Epoch 34/150\n",
      "94/94 [==============================] - 0s 609us/step - loss: 0.1473 - mean_squared_error: 0.1473\n",
      "Epoch 35/150\n",
      "94/94 [==============================] - 0s 610us/step - loss: 0.1445 - mean_squared_error: 0.1445\n",
      "Epoch 36/150\n",
      "94/94 [==============================] - 0s 611us/step - loss: 0.1505 - mean_squared_error: 0.1505\n",
      "Epoch 37/150\n",
      "94/94 [==============================] - 0s 661us/step - loss: 0.1487 - mean_squared_error: 0.1487\n",
      "Epoch 38/150\n",
      "94/94 [==============================] - 0s 608us/step - loss: 0.1583 - mean_squared_error: 0.1583\n",
      "Epoch 39/150\n",
      "94/94 [==============================] - 0s 598us/step - loss: 0.1453 - mean_squared_error: 0.1453\n",
      "Epoch 40/150\n",
      "94/94 [==============================] - 0s 616us/step - loss: 0.1497 - mean_squared_error: 0.1497\n",
      "Epoch 41/150\n",
      "94/94 [==============================] - 0s 676us/step - loss: 0.1465 - mean_squared_error: 0.1465\n",
      "Epoch 42/150\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1520 - mean_squared_error: 0.1520\n",
      "Epoch 43/150\n",
      "94/94 [==============================] - 0s 563us/step - loss: 0.1548 - mean_squared_error: 0.1548\n",
      "Epoch 44/150\n",
      "94/94 [==============================] - 0s 566us/step - loss: 0.1519 - mean_squared_error: 0.1519\n",
      "Epoch 45/150\n",
      "94/94 [==============================] - 0s 516us/step - loss: 0.1522 - mean_squared_error: 0.1522\n",
      "Epoch 46/150\n",
      "94/94 [==============================] - 0s 614us/step - loss: 0.1505 - mean_squared_error: 0.1505\n",
      "Epoch 47/150\n",
      "94/94 [==============================] - 0s 582us/step - loss: 0.1484 - mean_squared_error: 0.1484\n",
      "Epoch 48/150\n",
      "94/94 [==============================] - 0s 538us/step - loss: 0.1542 - mean_squared_error: 0.1542\n",
      "Epoch 49/150\n",
      "94/94 [==============================] - 0s 524us/step - loss: 0.1497 - mean_squared_error: 0.1497\n",
      "Epoch 50/150\n",
      "94/94 [==============================] - 0s 532us/step - loss: 0.1462 - mean_squared_error: 0.1462\n",
      "Epoch 51/150\n",
      "94/94 [==============================] - 0s 656us/step - loss: 0.1565 - mean_squared_error: 0.1565\n",
      "Epoch 52/150\n",
      "94/94 [==============================] - 0s 592us/step - loss: 0.1508 - mean_squared_error: 0.1508\n",
      "Epoch 53/150\n",
      "94/94 [==============================] - 0s 525us/step - loss: 0.1511 - mean_squared_error: 0.1511\n",
      "Epoch 54/150\n",
      "94/94 [==============================] - 0s 520us/step - loss: 0.1462 - mean_squared_error: 0.1462\n",
      "Epoch 55/150\n",
      "94/94 [==============================] - 0s 520us/step - loss: 0.1550 - mean_squared_error: 0.1550\n",
      "Epoch 56/150\n",
      "94/94 [==============================] - 0s 523us/step - loss: 0.1508 - mean_squared_error: 0.1508\n",
      "Epoch 57/150\n",
      "94/94 [==============================] - 0s 516us/step - loss: 0.1453 - mean_squared_error: 0.1453\n",
      "Epoch 58/150\n",
      "94/94 [==============================] - 0s 506us/step - loss: 0.1473 - mean_squared_error: 0.1473\n",
      "Epoch 59/150\n",
      "94/94 [==============================] - 0s 512us/step - loss: 0.1562 - mean_squared_error: 0.1562\n",
      "Epoch 60/150\n",
      "94/94 [==============================] - 0s 538us/step - loss: 0.1485 - mean_squared_error: 0.1485\n",
      "Epoch 61/150\n",
      "94/94 [==============================] - 0s 512us/step - loss: 0.1587 - mean_squared_error: 0.1587\n",
      "Epoch 62/150\n",
      "94/94 [==============================] - 0s 513us/step - loss: 0.1451 - mean_squared_error: 0.1451\n",
      "Epoch 63/150\n",
      "94/94 [==============================] - 0s 523us/step - loss: 0.1477 - mean_squared_error: 0.1477\n",
      "Epoch 64/150\n",
      "94/94 [==============================] - 0s 514us/step - loss: 0.1572 - mean_squared_error: 0.1572\n",
      "Epoch 65/150\n",
      "94/94 [==============================] - 0s 517us/step - loss: 0.1480 - mean_squared_error: 0.1480\n",
      "Epoch 66/150\n",
      "94/94 [==============================] - 0s 513us/step - loss: 0.1515 - mean_squared_error: 0.1515\n",
      "Epoch 67/150\n",
      "94/94 [==============================] - 0s 515us/step - loss: 0.1549 - mean_squared_error: 0.1549\n",
      "Epoch 68/150\n",
      "94/94 [==============================] - 0s 513us/step - loss: 0.1430 - mean_squared_error: 0.1430\n",
      "Epoch 69/150\n",
      "94/94 [==============================] - 0s 525us/step - loss: 0.1443 - mean_squared_error: 0.1443\n",
      "Epoch 70/150\n",
      "94/94 [==============================] - 0s 526us/step - loss: 0.1537 - mean_squared_error: 0.1537\n",
      "Epoch 71/150\n",
      "94/94 [==============================] - 0s 514us/step - loss: 0.1517 - mean_squared_error: 0.1517\n",
      "Epoch 72/150\n",
      "94/94 [==============================] - 0s 506us/step - loss: 0.1506 - mean_squared_error: 0.1506\n",
      "Epoch 73/150\n",
      "94/94 [==============================] - 0s 509us/step - loss: 0.1457 - mean_squared_error: 0.1457\n",
      "Epoch 74/150\n",
      "94/94 [==============================] - 0s 512us/step - loss: 0.1508 - mean_squared_error: 0.1508\n",
      "Epoch 75/150\n",
      "94/94 [==============================] - 0s 547us/step - loss: 0.1577 - mean_squared_error: 0.1577\n",
      "Epoch 76/150\n",
      "94/94 [==============================] - 0s 620us/step - loss: 0.1397 - mean_squared_error: 0.1397\n",
      "Epoch 77/150\n",
      "94/94 [==============================] - 0s 503us/step - loss: 0.1530 - mean_squared_error: 0.1530\n",
      "Epoch 78/150\n",
      "94/94 [==============================] - 0s 500us/step - loss: 0.1493 - mean_squared_error: 0.1493\n",
      "Epoch 79/150\n",
      "94/94 [==============================] - 0s 521us/step - loss: 0.1442 - mean_squared_error: 0.1442\n",
      "Epoch 80/150\n",
      "94/94 [==============================] - 0s 517us/step - loss: 0.1445 - mean_squared_error: 0.1445\n",
      "Epoch 81/150\n",
      "94/94 [==============================] - 0s 503us/step - loss: 0.1566 - mean_squared_error: 0.1566\n",
      "Epoch 82/150\n",
      "94/94 [==============================] - 0s 511us/step - loss: 0.1444 - mean_squared_error: 0.1444\n",
      "Epoch 83/150\n",
      "94/94 [==============================] - 0s 514us/step - loss: 0.1486 - mean_squared_error: 0.1486\n",
      "Epoch 84/150\n",
      "94/94 [==============================] - 0s 495us/step - loss: 0.1441 - mean_squared_error: 0.1441\n",
      "Epoch 85/150\n",
      "94/94 [==============================] - 0s 495us/step - loss: 0.1483 - mean_squared_error: 0.1483\n",
      "Epoch 86/150\n",
      "94/94 [==============================] - 0s 491us/step - loss: 0.1505 - mean_squared_error: 0.1505\n",
      "Epoch 87/150\n",
      "94/94 [==============================] - 0s 496us/step - loss: 0.1447 - mean_squared_error: 0.1447\n",
      "Epoch 88/150\n",
      "94/94 [==============================] - 0s 492us/step - loss: 0.1456 - mean_squared_error: 0.1456\n",
      "Epoch 89/150\n",
      "94/94 [==============================] - 0s 494us/step - loss: 0.1459 - mean_squared_error: 0.1459\n",
      "Epoch 90/150\n",
      "94/94 [==============================] - 0s 491us/step - loss: 0.1497 - mean_squared_error: 0.1497\n",
      "Epoch 91/150\n",
      "94/94 [==============================] - 0s 496us/step - loss: 0.1514 - mean_squared_error: 0.1514\n",
      "Epoch 92/150\n",
      "94/94 [==============================] - 0s 490us/step - loss: 0.1457 - mean_squared_error: 0.1457\n",
      "Epoch 93/150\n",
      "94/94 [==============================] - 0s 499us/step - loss: 0.1507 - mean_squared_error: 0.1507\n",
      "Epoch 94/150\n",
      "94/94 [==============================] - 0s 594us/step - loss: 0.1519 - mean_squared_error: 0.1519\n",
      "Epoch 95/150\n",
      "94/94 [==============================] - 0s 616us/step - loss: 0.1496 - mean_squared_error: 0.1496\n",
      "Epoch 96/150\n",
      "94/94 [==============================] - 0s 594us/step - loss: 0.1498 - mean_squared_error: 0.1498\n",
      "Epoch 97/150\n",
      "94/94 [==============================] - 0s 632us/step - loss: 0.1492 - mean_squared_error: 0.1492\n",
      "Epoch 98/150\n",
      "94/94 [==============================] - 0s 584us/step - loss: 0.1583 - mean_squared_error: 0.1583\n",
      "Epoch 99/150\n",
      "94/94 [==============================] - 0s 673us/step - loss: 0.1473 - mean_squared_error: 0.1473\n",
      "Epoch 100/150\n",
      "94/94 [==============================] - 0s 634us/step - loss: 0.1447 - mean_squared_error: 0.1447\n",
      "Epoch 101/150\n",
      "94/94 [==============================] - 0s 579us/step - loss: 0.1469 - mean_squared_error: 0.1469\n",
      "Epoch 102/150\n",
      "94/94 [==============================] - 0s 586us/step - loss: 0.1477 - mean_squared_error: 0.1477\n",
      "Epoch 103/150\n",
      "94/94 [==============================] - 0s 566us/step - loss: 0.1515 - mean_squared_error: 0.1515\n",
      "Epoch 104/150\n",
      "94/94 [==============================] - 0s 590us/step - loss: 0.1551 - mean_squared_error: 0.1551\n",
      "Epoch 105/150\n",
      "94/94 [==============================] - 0s 584us/step - loss: 0.1546 - mean_squared_error: 0.1546\n",
      "Epoch 106/150\n",
      "94/94 [==============================] - 0s 581us/step - loss: 0.1532 - mean_squared_error: 0.1532\n",
      "Epoch 107/150\n",
      "94/94 [==============================] - 0s 500us/step - loss: 0.1461 - mean_squared_error: 0.1461\n",
      "Epoch 108/150\n",
      "94/94 [==============================] - 0s 492us/step - loss: 0.1489 - mean_squared_error: 0.1489\n",
      "Epoch 109/150\n",
      "94/94 [==============================] - 0s 499us/step - loss: 0.1497 - mean_squared_error: 0.1497\n",
      "Epoch 110/150\n",
      "94/94 [==============================] - 0s 495us/step - loss: 0.1499 - mean_squared_error: 0.1499\n",
      "Epoch 111/150\n",
      "94/94 [==============================] - 0s 501us/step - loss: 0.1463 - mean_squared_error: 0.1463\n",
      "Epoch 112/150\n",
      "94/94 [==============================] - 0s 503us/step - loss: 0.1501 - mean_squared_error: 0.1501\n",
      "Epoch 113/150\n",
      "94/94 [==============================] - 0s 498us/step - loss: 0.1512 - mean_squared_error: 0.1512\n",
      "Epoch 114/150\n",
      "94/94 [==============================] - 0s 500us/step - loss: 0.1464 - mean_squared_error: 0.1464\n",
      "Epoch 115/150\n",
      "94/94 [==============================] - 0s 506us/step - loss: 0.1518 - mean_squared_error: 0.1518\n",
      "Epoch 116/150\n",
      "94/94 [==============================] - 0s 505us/step - loss: 0.1528 - mean_squared_error: 0.1528\n",
      "Epoch 117/150\n",
      "94/94 [==============================] - 0s 504us/step - loss: 0.1462 - mean_squared_error: 0.1462\n",
      "Epoch 118/150\n",
      "94/94 [==============================] - 0s 531us/step - loss: 0.1522 - mean_squared_error: 0.1522\n",
      "Epoch 119/150\n",
      "94/94 [==============================] - 0s 538us/step - loss: 0.1474 - mean_squared_error: 0.1474\n",
      "Epoch 120/150\n",
      "94/94 [==============================] - 0s 509us/step - loss: 0.1486 - mean_squared_error: 0.1486\n",
      "Epoch 121/150\n",
      "94/94 [==============================] - 0s 504us/step - loss: 0.1520 - mean_squared_error: 0.1520\n",
      "Epoch 122/150\n",
      "94/94 [==============================] - 0s 502us/step - loss: 0.1461 - mean_squared_error: 0.1461\n",
      "Epoch 123/150\n",
      "94/94 [==============================] - 0s 503us/step - loss: 0.1556 - mean_squared_error: 0.1556\n",
      "Epoch 124/150\n",
      "94/94 [==============================] - 0s 505us/step - loss: 0.1483 - mean_squared_error: 0.1483\n",
      "Epoch 125/150\n",
      "94/94 [==============================] - 0s 502us/step - loss: 0.1468 - mean_squared_error: 0.1468\n",
      "Epoch 126/150\n",
      "94/94 [==============================] - 0s 499us/step - loss: 0.1497 - mean_squared_error: 0.1497\n",
      "Epoch 127/150\n",
      "94/94 [==============================] - 0s 503us/step - loss: 0.1554 - mean_squared_error: 0.1554\n",
      "Epoch 128/150\n",
      "94/94 [==============================] - 0s 498us/step - loss: 0.1477 - mean_squared_error: 0.1477\n",
      "Epoch 129/150\n",
      "94/94 [==============================] - 0s 501us/step - loss: 0.1531 - mean_squared_error: 0.1531\n",
      "Epoch 130/150\n",
      "94/94 [==============================] - 0s 490us/step - loss: 0.1465 - mean_squared_error: 0.1465\n",
      "Epoch 131/150\n",
      "94/94 [==============================] - 0s 536us/step - loss: 0.1468 - mean_squared_error: 0.1468\n",
      "Epoch 132/150\n",
      "94/94 [==============================] - 0s 586us/step - loss: 0.1493 - mean_squared_error: 0.1493\n",
      "Epoch 133/150\n",
      "94/94 [==============================] - 0s 524us/step - loss: 0.1517 - mean_squared_error: 0.1517\n",
      "Epoch 134/150\n",
      "94/94 [==============================] - 0s 491us/step - loss: 0.1480 - mean_squared_error: 0.1480\n",
      "Epoch 135/150\n",
      "94/94 [==============================] - 0s 497us/step - loss: 0.1468 - mean_squared_error: 0.1468\n",
      "Epoch 136/150\n",
      "94/94 [==============================] - 0s 521us/step - loss: 0.1446 - mean_squared_error: 0.1446\n",
      "Epoch 137/150\n",
      "94/94 [==============================] - 0s 499us/step - loss: 0.1491 - mean_squared_error: 0.1491\n",
      "Epoch 138/150\n",
      "94/94 [==============================] - 0s 507us/step - loss: 0.1485 - mean_squared_error: 0.1485\n",
      "Epoch 139/150\n",
      "94/94 [==============================] - 0s 512us/step - loss: 0.1466 - mean_squared_error: 0.1466\n",
      "Epoch 140/150\n",
      "94/94 [==============================] - 0s 500us/step - loss: 0.1479 - mean_squared_error: 0.1479\n",
      "Epoch 141/150\n",
      "94/94 [==============================] - 0s 519us/step - loss: 0.1487 - mean_squared_error: 0.1487\n",
      "Epoch 142/150\n",
      "94/94 [==============================] - 0s 783us/step - loss: 0.1505 - mean_squared_error: 0.1505\n",
      "Epoch 143/150\n",
      "94/94 [==============================] - 0s 797us/step - loss: 0.1494 - mean_squared_error: 0.1494\n",
      "Epoch 144/150\n",
      "94/94 [==============================] - 0s 606us/step - loss: 0.1533 - mean_squared_error: 0.1533\n",
      "Epoch 145/150\n",
      "94/94 [==============================] - 0s 672us/step - loss: 0.1456 - mean_squared_error: 0.1456\n",
      "Epoch 146/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 694us/step - loss: 0.1535 - mean_squared_error: 0.1535\n",
      "Epoch 147/150\n",
      "94/94 [==============================] - 0s 635us/step - loss: 0.1502 - mean_squared_error: 0.1502\n",
      "Epoch 148/150\n",
      "94/94 [==============================] - 0s 715us/step - loss: 0.1517 - mean_squared_error: 0.1517\n",
      "Epoch 149/150\n",
      "94/94 [==============================] - 0s 576us/step - loss: 0.1517 - mean_squared_error: 0.1517\n",
      "Epoch 150/150\n",
      "94/94 [==============================] - 0s 630us/step - loss: 0.1504 - mean_squared_error: 0.1504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb788f9f670>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile the keras model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fZp0hyBI7I2V",
    "outputId": "d0b743b6-744c-4a94-9f07-fb32ecf3fa04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb789384ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1349 - mean_squared_error: 0.1349\n",
      "test loss, test mse: [0.1349479705095291, 0.1349479705095291]\n"
     ]
    }
   ],
   "source": [
    "# evaluate the keras model\n",
    "# _, mse = model.evaluate(X_test, y_test)\n",
    "# print('MSE: %.2f' % (mse*100))\n",
    "results = model.evaluate(X_test, y_test, batch_size=128)\n",
    "print(\"test loss, test mse:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hgdpVX6X7Let"
   },
   "outputs": [],
   "source": [
    "# Old code kept for reference\n",
    "# ceo_data_small['gender'] = ceo_data_small['gender'].apply(lambda x: int(x == \"FEMALE\"))\n",
    "# ceo_data_small['DateFiled'] = ceo_data_small['DateFiled'].apply(lambda x: pd.to_datetime(x) - pd.to_datetime(\"2020-01-01\"))\n",
    "# ceo_data_small['DateFiled'] = ceo_data_small['DateFiled'].apply(lambda x: x.days)\n",
    "# ceo_data_small['becameceo'] = ceo_data_small['becameceo'].apply(lambda x: pd.to_datetime(\"2021-01-01\") - pd.to_datetime(x))\n",
    "# ceo_data_small['becameceo'] = ceo_data_small['becameceo'].apply(lambda x: x.days)\n",
    "# #ceo_data_small['state'] = ceo_data_small['state'].astype('category')\n",
    "# ceo_data_small.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wrzAZzW_RU0l",
    "outputId": "9acc557e-7378-44fe-9d0e-617195333d12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.022603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:104: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# run the data on xgboost model\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "\n",
    "# train xgb classifier\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 100)\n",
    "xg_reg.fit(X_train,y_train)\n",
    "\n",
    "preds = xg_reg.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, preds)\n",
    "print(\"MSE: %f\" % (mse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01340752 0.17245153 0.06694279 0.1570927  0.03432391 0.00379894\n",
      " 0.01564131 0.         0.05207348 0.03838645 0.14670637 0.25448808\n",
      " 0.04468696]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAO+0lEQVR4nO3df4xdaV3H8ffHqY2yLlllhx+2xdakARuyK5vJsroGsuKSliWUP/yjBBdENs2arYCRuCUm/GNimkiMGBeaZqlABDYGt7GRsj+CJsTAmk4Rl+0uC5NS6djFzgICSkKpfP3jnobLcKdzpp2Z23nm/Uom957nPM+539tOP33mmXPOTVUhSWrXT427AEnSyjLoJalxBr0kNc6gl6TGGfSS1LgN4y5glOuvv762bt067jIkac04ceLEs1U1OWrfVRn0W7duZXp6etxlSNKakeQ/Ftrn0o0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDWu15WxSXYC7wMmgPur6sC8/W8C7u02/wf4/ar6927faeC7wP8BF6pqanlKl6TFbd3/yWU71ukDdyzbsVbTokGfZAK4D7gdmAWOJzlaVU8Odfsq8Kqq+laSXcAh4BVD+2+rqmeXsW5JUk99lm5uBmaq6lRVnQceAHYPd6iqz1bVt7rNx4DNy1umJOly9Qn6TcCZoe3Zrm0hbwM+NbRdwCNJTiTZu9CgJHuTTCeZnpub61GWJKmPPmv0GdE28hPFk9zGIOh/Y6j51qo6m+T5wKNJvlRVn/mJA1YdYrDkw9TUlJ9YLknLpM+MfhbYMrS9GTg7v1OSG4D7gd1V9Y2L7VV1tns8BxxhsBQkSVolfYL+OLA9ybYkG4E9wNHhDkleDDwI3FlVXx5qvybJtRefA68Bnliu4iVJi1t06aaqLiTZBzzM4PTKw1V1Msnd3f6DwHuA5wHvTwI/Oo3yBcCRrm0D8LGqemhF3okkaaRe59FX1THg2Ly2g0PP7wLuGjHuFHDjFdYoSboCXhkrSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJalyvoE+yM8nTSWaS7B+x/01JHu++Ppvkxr5jJUkra9GgTzIB3AfsAnYAb0yyY163rwKvqqobgD8FDi1hrCRpBfWZ0d8MzFTVqao6DzwA7B7uUFWfrapvdZuPAZv7jpUkraw+Qb8JODO0Pdu1LeRtwKeWOjbJ3iTTSabn5uZ6lCVJ6qNP0GdEW43smNzGIOjvXerYqjpUVVNVNTU5OdmjLElSHxt69JkFtgxtbwbOzu+U5AbgfmBXVX1jKWMlSSunz4z+OLA9ybYkG4E9wNHhDkleDDwI3FlVX17KWEnSylp0Rl9VF5LsAx4GJoDDVXUyyd3d/oPAe4DnAe9PAnChW4YZOXaF3oskaYQ+SzdU1THg2Ly2g0PP7wLu6jtWkrR6vDJWkhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktS4Xh88oh/Zuv+Ty3as0wfuWLZjSdJCnNFLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXHe1Gwd8YZs0vrkjF6SGmfQS1LjegV9kp1Jnk4yk2T/iP0vTfK5JN9P8q55+04n+WKSLySZXq7CJUn9LLpGn2QCuA+4HZgFjic5WlVPDnX7JvB24A0LHOa2qnr2CmuVJF2GPjP6m4GZqjpVVeeBB4Ddwx2q6lxVHQd+sAI1SpKuQJ+g3wScGdqe7dr6KuCRJCeS7F2oU5K9SaaTTM/NzS3h8JKkS+kT9BnRVkt4jVur6iZgF3BPkleO6lRVh6pqqqqmJicnl3B4SdKl9DmPfhbYMrS9GTjb9wWq6mz3eC7JEQZLQZ9ZSpGS2uY1Hiurz4z+OLA9ybYkG4E9wNE+B09yTZJrLz4HXgM8cbnFSpKWbtEZfVVdSLIPeBiYAA5X1ckkd3f7DyZ5ITANPBf4YZJ3AjuA64EjSS6+1seq6qEVeSeSpJF63QKhqo4Bx+a1HRx6/nUGSzrzfQe48UoKlCRdGa+MlaTGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcb2CPsnOJE8nmUmyf8T+lyb5XJLvJ3nXUsZKklbWokGfZAK4D9gF7ADemGTHvG7fBN4OvPcyxkqSVlCfGf3NwExVnaqq88ADwO7hDlV1rqqOAz9Y6lhJ0srqE/SbgDND27NdWx+9xybZm2Q6yfTc3FzPw0uSFtMn6DOirXoev/fYqjpUVVNVNTU5Odnz8JKkxfQJ+llgy9D2ZuBsz+NfyVhJ0jLoE/THge1JtiXZCOwBjvY8/pWMlSQtgw2LdaiqC0n2AQ8DE8DhqjqZ5O5u/8EkLwSmgecCP0zyTmBHVX1n1NgVei+SpBEWDXqAqjoGHJvXdnDo+dcZLMv0GitJWj1eGStJjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUuA3jLkA/snX/J5ftWKcP3LFsx5K0tjmjl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktS4XkGfZGeSp5PMJNk/Yn+S/FW3//EkNw3tO53ki0m+kGR6OYuXJC1u0XvdJJkA7gNuB2aB40mOVtWTQ912Adu7r1cAH+geL7qtqp5dtqol/Rjvk6RL6TOjvxmYqapTVXUeeADYPa/PbuAjNfAYcF2SFy1zrZKky9An6DcBZ4a2Z7u2vn0KeCTJiSR7F3qRJHuTTCeZnpub61GWJKmPPkGfEW21hD63VtVNDJZ37knyylEvUlWHqmqqqqYmJyd7lCVJ6qNP0M8CW4a2NwNn+/apqouP54AjDJaCJEmrpE/QHwe2J9mWZCOwBzg6r89R4M3d2Te3AN+uqmeSXJPkWoAk1wCvAZ5YxvolSYtY9KybqrqQZB/wMDABHK6qk0nu7vYfBI4BrwVmgO8Bb+2GvwA4kuTia32sqh5a9nchSWOyFs546vVRglV1jEGYD7cdHHpewD0jxp0CbrzCGiVJV8ArYyWpcQa9JDXOoJekxhn0ktS4Xr+MlbS+rYUzS7QwZ/SS1DiDXpIa59KNlo0/3ktXJ2f0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalx3qZYwlssq23O6CWpcc3N6J2ZSdKPc0YvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1Ljep1Hn2Qn8D5gAri/qg7M259u/2uB7wG/W1Wf7zNW6strJKTLs+iMPskEcB+wC9gBvDHJjnnddgHbu6+9wAeWMFaStIL6LN3cDMxU1amqOg88AOye12c38JEaeAy4LsmLeo6VJK2gVNWlOyS/Deysqru67TuBV1TVvqE+/wgcqKp/6bY/DdwLbF1s7NAx9jL4aQDgJcDTV/bWLul64NkVPP5KW8v1r+XawfrHaS3XDitf/y9V1eSoHX3W6DOibf7/Dgv16TN20Fh1CDjUo54rlmS6qqZW47VWwlqufy3XDtY/Tmu5dhhv/X2CfhbYMrS9GTjbs8/GHmMlSSuozxr9cWB7km1JNgJ7gKPz+hwF3pyBW4BvV9UzPcdKklbQojP6qrqQZB/wMINTJA9X1ckkd3f7DwLHGJxaOcPg9Mq3XmrsiryTpVmVJaIVtJbrX8u1g/WP01quHcZY/6K/jJUkrW1eGStJjTPoJalx6y7ok+xM8nSSmST7x11PX0m2JPnnJE8lOZnkHeOu6XIkmUjyb921F2tKkuuSfCLJl7q/h18bd019JfnD7vvmiSQfT/Iz467pUpIcTnIuyRNDbb+Q5NEkX+kef36cNS5kgdr/vPu+eTzJkSTXrWZN6yro1/gtGS4Af1RVvwLcAtyzhmof9g7gqXEXcZneBzxUVS8FbmSNvI8km4C3A1NV9TIGJ0bsGW9Vi/oQsHNe237g01W1Hfh0t301+hA/WfujwMuq6gbgy8C7V7OgdRX0rOFbMlTVMxdvFFdV32UQMpvGW9XSJNkM3AHcP+5alirJc4FXAh8EqKrzVfXfYy1qaTYAP5tkA/AcrvLrWarqM8A35zXvBj7cPf8w8IbVrKmvUbVX1SNVdaHbfIzBNUWrZr0F/SbgzND2LGssLAGSbAVeDvzrmEtZqr8E/hj44ZjruBy/DMwBf9MtPd2f5JpxF9VHVf0n8F7ga8AzDK5zeWS8VV2WF3TX59A9Pn/M9Vyu3wM+tZovuN6CvvctGa5WSX4O+HvgnVX1nXHX01eS1wHnqurEuGu5TBuAm4APVNXLgf/l6l06+DHdWvZuYBvwi8A1SX5nvFWtT0n+hMEy7EdX83XXW9D3uZ3DVSvJTzMI+Y9W1YPjrmeJbgVen+Q0gyWz30zyt+MtaUlmgdmquvhT1CcYBP9a8FvAV6tqrqp+ADwI/PqYa7oc/9XdFZfu8dyY61mSJG8BXge8qVb5Aqb1FvRr9pYM3Ye7fBB4qqr+Ytz1LFVVvbuqNlfVVgZ/7v9UVWtmVllVXwfOJHlJ1/Rq4MkxlrQUXwNuSfKc7vvo1ayRXyTPcxR4S/f8LcA/jLGWJek+gOle4PVV9b3Vfv11FfTdL0Mu3pLhKeDvrpJbMvRxK3Ang5nwF7qv1467qHXmD4CPJnkc+FXgz8ZbTj/dTyGfAD4PfJHBv/ur+nYCST4OfA54SZLZJG8DDgC3J/kKcHu3fdVZoPa/Bq4FHu3+7R5c1Zq8BYIktW1dzeglaT0y6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1Lj/h/YbV1wJrc7SgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(xg_reg.feature_importances_)\n",
    "# plot\n",
    "pyplot.bar(range(len(xg_reg.feature_importances_)), xg_reg.feature_importances_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "97biTpRpURFN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.025766\n"
     ]
    }
   ],
   "source": [
    "# Using support vector machine\n",
    "from sklearn import svm\n",
    "regr = svm.SVR()\n",
    "regr.fit(X_train, y_train)\n",
    "preds = regr.predict(X_test)\n",
    "mse = mean_squared_error(y_test, preds)\n",
    "print(\"MSE: %f\" % (mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.023282\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "from sklearn.linear_model import Ridge\n",
    "clf = Ridge(alpha=1.0)\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_test)\n",
    "mse = mean_squared_error(y_test, preds)\n",
    "print(\"MSE: %f\" % (mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.023278\n",
      "0.10209314728639829\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "# Lineaer Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "preds = reg.predict(X_test)\n",
    "mse = mean_squared_error(y_test, preds)\n",
    "print(\"MSE: %f\" % (mse))\n",
    "print(r2_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ML_Model_Stock_Return.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
